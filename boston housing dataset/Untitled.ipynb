{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Input,Dense,Dropout,Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "3   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "4   7  0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311   \n",
       "\n",
       "   ptratio   black  lstat  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     18.7  394.63   2.94  33.4  \n",
       "3     18.7  396.90   5.33  36.2  \n",
       "4     15.2  395.60  12.43  22.9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333 entries, 0 to 332\n",
      "Data columns (total 15 columns):\n",
      "ID         333 non-null int64\n",
      "crim       333 non-null float64\n",
      "zn         333 non-null float64\n",
      "indus      333 non-null float64\n",
      "chas       333 non-null int64\n",
      "nox        333 non-null float64\n",
      "rm         333 non-null float64\n",
      "age        333 non-null float64\n",
      "dis        333 non-null float64\n",
      "rad        333 non-null int64\n",
      "tax        333 non-null int64\n",
      "ptratio    333 non-null float64\n",
      "black      333 non-null float64\n",
      "lstat      333 non-null float64\n",
      "medv       333 non-null float64\n",
      "dtypes: float64(11), int64(4)\n",
      "memory usage: 39.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:,1:-1]\n",
    "Y_train = data[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 1) (333, 13)\n"
     ]
    }
   ],
   "source": [
    "Y_train.reshape((333,-1))\n",
    "print(Y_train.shape,X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "un = np.unique(X_train[:,3])\n",
    "print(un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18  0.    0.    0.    0.125 0.125 0.125 0.125 0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.75  0.75\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.21  0.21  0.21  0.75  0.9\n",
      " 0.85  1.    0.25  0.25  0.25  0.25  0.175 0.8   0.8   0.125 0.125 0.\n",
      " 0.    0.    0.    0.    0.    0.    0.25  0.25  0.25  0.    0.    0.\n",
      " 0.    0.    0.    0.    0.28  0.28  0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.45\n",
      " 0.45  0.45  0.45  0.45  0.6   0.6   0.8   0.95  0.825 0.95  0.95  0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.3   0.3   0.3   0.22\n",
      " 0.22  0.22  0.22  0.22  0.22  0.22  0.2   0.2   0.2   0.2   0.2   0.2\n",
      " 0.2   0.2   0.2   0.2   0.2   0.4   0.2   0.2   0.2   0.9   0.9   0.55\n",
      " 0.8   0.525 0.8   0.8   0.    0.    0.    0.34  0.34  0.34  0.33  0.33\n",
      " 0.33  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.35  0.\n",
      " 0.55  0.55  0.85  0.8   0.4   0.6   0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(333, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalisation\n",
    "\n",
    "X_train[:,1] = (X_train[:,1]-np.min(X_train[:,1]) )/np.max(X_train[:,1])\n",
    "print(X_train[:,1])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 13)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train[:,0] = (X_train[:,0]-np.min(X_train[:,0]) )/np.max(X_train[:,0])\n",
    "X_train[:,2] = (X_train[:,2]-np.min(X_train[:,2]) )/np.max(X_train[:,2])\n",
    "X_train[:,4] = (X_train[:,4]-np.min(X_train[:,4]) )/np.max(X_train[:,4])\n",
    "X_train[:,5] = (X_train[:,5]-np.min(X_train[:,5]) )/np.max(X_train[:,5])\n",
    "Y_train[:,] = (Y_train[:,]-np.min(Y_train[:,]) )/np.max(Y_train[:,])\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3200e-03 1.8000e-01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [3.2370e-02 0.0000e+00 2.1800e+00 ... 1.8700e+01 3.9463e+02 2.9400e+00]\n",
      " ...\n",
      " [4.5270e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 9.0800e+00]\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                448       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,625\n",
      "Trainable params: 2,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=(13)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 266 samples, validate on 67 samples\n",
      "Epoch 1/30\n",
      "266/266 [==============================] - 0s 675us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "266/266 [==============================] - 0s 89us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 3/30\n",
      "266/266 [==============================] - 0s 59us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 4/30\n",
      "266/266 [==============================] - 0s 127us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 5/30\n",
      "266/266 [==============================] - 0s 81us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 6/30\n",
      "266/266 [==============================] - 0s 86us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 7/30\n",
      "266/266 [==============================] - 0s 77us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 8/30\n",
      "266/266 [==============================] - 0s 68us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 9/30\n",
      "266/266 [==============================] - 0s 89us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 10/30\n",
      "266/266 [==============================] - 0s 66us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 11/30\n",
      "266/266 [==============================] - 0s 84us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 12/30\n",
      "266/266 [==============================] - 0s 71us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 13/30\n",
      "266/266 [==============================] - 0s 85us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 14/30\n",
      "266/266 [==============================] - 0s 71us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 15/30\n",
      "266/266 [==============================] - 0s 93us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 16/30\n",
      "266/266 [==============================] - 0s 99us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 17/30\n",
      "266/266 [==============================] - 0s 78us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 18/30\n",
      "266/266 [==============================] - 0s 59us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 19/30\n",
      "266/266 [==============================] - 0s 74us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 20/30\n",
      "266/266 [==============================] - 0s 88us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 21/30\n",
      "266/266 [==============================] - 0s 66us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 22/30\n",
      "266/266 [==============================] - 0s 78us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 23/30\n",
      "266/266 [==============================] - 0s 101us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 24/30\n",
      "266/266 [==============================] - 0s 69us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 25/30\n",
      "266/266 [==============================] - 0s 82us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 26/30\n",
      "266/266 [==============================] - 0s 75us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 27/30\n",
      "266/266 [==============================] - 0s 89us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 28/30\n",
      "266/266 [==============================] - 0s 71us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 29/30\n",
      "266/266 [==============================] - 0s 72us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n",
      "Epoch 30/30\n",
      "266/266 [==============================] - 0s 71us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.6211 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist =  model.fit(X_train,Y_train,\n",
    "                  epochs=30, \n",
    "                  shuffle=True,  \n",
    "                  batch_size=32,\n",
    "                  validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
