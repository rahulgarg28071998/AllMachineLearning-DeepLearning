{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Chains\n",
    "\n",
    "### Exercise\n",
    "In this exercise, we will build Markov Chain Model from scratch. We will train our model on Eminem rap lyrics data collected from the internet. You will work in Python and we will use one numpy function `np.random.choice` in the sampling method. Your task is to complete the methods `generateTransitionTable` which will generate ctx-nextLetter transition pairs, and maintains the corresponding frequency. Next task is to normalize frequencies to get a probability distribution over list of possible outputs given the context. This is done using function `convertFreqIntoProb` and is already implemented for you. At test time you will call `sample_next` method repeatedly to generate your sentence character by character, upto max length. The `sample_next` method accepts the last `order` sized window of characters to give the prediction. Complete the final exercise to generate random eminem rap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "(Helper Functions to go in a different file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(filename):\n",
    "    #loads a text file, and returns text\n",
    "    with open(filename) as f:\n",
    "        return f.read()\n",
    "\n",
    "text1 = load_text('./Data_Rap/lyrics1.txt')\n",
    "text2 = load_text('./Data_Rap/lyrics2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(*docs):\n",
    "    \"\"\"combines multiple text files into single data string\"\"\"\n",
    "    data = \"\"\n",
    "    for doc in docs:\n",
    "        data += ' '.join([word.lower() for word in doc.split('\\n')])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(text1,text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Chain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- Define the context ctx by slicing the `data` starting from index `ix` to `ix+order`\n",
    "- Define the `next_letter` to be picked from data,which is next character after the `order` sized window ends.\n",
    "- Update the frequency of ctx-next_letter transition by 1, set to 1 if the transiton doesn't exist\n",
    "- Use `np.random.choice(possible_letters,p=probabilities)` for sampling at test time.\n",
    "- Iteratively generate new characters upto max length and append them to the generated sentence at test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTransitionTable(data,order=4):\n",
    "    \"\"\"Creates a Transition Table, which stores the ctx-nextletter frequency, in nested dictionary\"\"\"\n",
    "    T = {}\n",
    "    for ix in range(len(data)-order):\n",
    "        #get the current 'order' sized window to create ctx-nextletter pair in Transtion Table\n",
    "        ctx = ______\n",
    "        #get the next letter in seqence at index order+\n",
    "        next_letter = _____\n",
    "\n",
    "        if T.get(ctx) is None:\n",
    "            #if the ctx doesn't exist in transition table, then create one.\n",
    "            T[ctx] = {}\n",
    "            T[ctx][next_letter] = ____\n",
    "        else:\n",
    "            # if transition pair ctx-next_letter doesn't exist, create one \n",
    "            if T[ctx].get(next_letter) is None:\n",
    "                #set the frequency to 1\n",
    "                T[ctx][next_letter] = _____\n",
    "            else:\n",
    "                #update the existing existing frequency by 1\n",
    "                T[ctx][next_letter] += _____\n",
    "                \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method\n",
    "def convertFreqIntoProb(T):\n",
    "    \"\"\"Converts Frequencies into Probabilities\"\"\"\n",
    "    for kx in T.keys():\n",
    "        s = float(sum(T[kx].values()))\n",
    "        for k in T[kx].keys():\n",
    "            T[kx][k] = T[kx][k]/s    \n",
    "            \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainMarkovChain(data,order=4):\n",
    "    #Get the transiton table using the function defined above\n",
    "    T = _______________\n",
    "    #Normalise frequencies to make probabilities\n",
    "    T = convertFreqIntoProb(T)\n",
    "    return T\n",
    "\n",
    "T = trainMarkovChain(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling at Test Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next(ctx,T):\n",
    "    \"\"\"Samples a new character based on past context, and prob distribution defined in T[ctx]\"\"\"\n",
    "    possible = T.get(ctx)\n",
    "    if possible is None:\n",
    "        return \" \"\n",
    "    possible_letters = list(possible.keys())\n",
    "    keys_probs = [possible[kx] for kx in possible_letters]\n",
    "    \n",
    "    #Implement Sampling using \n",
    "    sampled_letter =  ________________\n",
    "    return sampled_letter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateText(ctx,maxLen=500):\n",
    "    np.random.seed(1)\n",
    "    sentence = '' + ctx\n",
    "    order = 4\n",
    "    for ix in range(maxLen):\n",
    "        #Generate new letter by sampling\n",
    "        next_letter = ______\n",
    "        #Append the letter to the generated sentence so far\n",
    "        sentence += _______\n",
    "        #Update the context to conside last 'order' size window\n",
    "        ctx = sentence[-order:]\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentence = generateText(\"sing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
